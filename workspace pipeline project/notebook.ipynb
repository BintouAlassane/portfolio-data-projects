{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef36f535-4bdc-4e2b-a22a-179372324b26",
   "metadata": {},
   "source": [
    "Walmart is the biggest retail store in the United States. Just like others, they have been expanding their e-commerce part of the business. By the end of 2022, e-commerce represented a roaring $80 billion in sales, which is 13% of total sales of Walmart. One of the main factors that affects their sales is public holidays, like the Super Bowl, Labour Day, Thanksgiving, and Christmas. \n",
    "\n",
    "In this project, you have been tasked with creating a data pipeline for the analysis of supply and demand around the holidays, along with conducting a preliminary analysis of the data. You will be working with two data sources: grocery sales and complementary data. You have been provided with the `grocery_sales` table in `PostgreSQL` database with the following features:\n",
    "\n",
    "# `grocery_sales`\n",
    "- `\"index\"` - unique ID of the row\n",
    "- `\"Store_ID\"` - the store number\n",
    "- `\"Date\"` - the week of sales\n",
    "- `\"Weekly_Sales\"` - sales for the given store\n",
    "\n",
    "Also, you have the `extra_data.parquet` file that contains complementary data:\n",
    "\n",
    "# `extra_data.parquet`\n",
    "- `\"IsHoliday\"` - Whether the week contains a public holiday - 1 if yes, 0 if no.\n",
    "- `\"Temperature\"` - Temperature on the day of sale\n",
    "- `\"Fuel_Price\"` - Cost of fuel in the region\n",
    "- `\"CPI\"` – Prevailing consumer price index\n",
    "- `\"Unemployment\"` - The prevailing unemployment rate\n",
    "- `\"MarkDown1\"`, `\"MarkDown2\"`, `\"MarkDown3\"`, `\"MarkDown4\"` - number of promotional markdowns\n",
    "- `\"Dept\"` - Department Number in each store\n",
    "- `\"Size\"` - size of the store\n",
    "- `\"Type\"` - type of the store (depends on `Size` column)\n",
    "\n",
    "You will need to merge those files and perform some data manipulations. The transformed DataFrame can then be stored as the `clean_data` variable containing the following columns:\n",
    "- `\"Store_ID\"`\n",
    "- `\"Month\"`\n",
    "- `\"Dept\"`\n",
    "- `\"IsHoliday\"`\n",
    "- `\"Weekly_Sales\"`\n",
    "- `\"CPI\"`\n",
    "- \"`\"Unemployment\"`\"\n",
    "\n",
    "After merging and cleaning the data, you will have to analyze monthly sales of Walmart and store the results of your analysis as the `agg_data` variable that should look like:\n",
    "\n",
    "|  Month | Weekly_Sales  | \n",
    "|---|---|\n",
    "| 1.0  |  33174.178494 |\n",
    "|  2.0 |  34333.326579 |\n",
    "|  ... | ...  |  \n",
    "\n",
    "Finally, you should save the `clean_data` and `agg_data` as the csv files.\n",
    "\n",
    "It is recommended to use `pandas` for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "281426c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (17.0.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (2024.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from fastparquet) (21.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from fastparquet) (2025.2.0)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from fastparquet) (2.9.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from fastparquet) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from fastparquet) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\bintou\\anaconda3\\envs\\new kernel\\lib\\site-packages (from packaging->fastparquet) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0d64ff1-a4ca-4a82-a8b4-e210244dedc1",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 38,
    "lastExecutedAt": 1736854024567,
    "lastExecutedByKernel": "675776d8-c451-4dd6-b157-a86dd2f071f2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\nimport os\n\n# Extract function is already implemented for you \ndef extract(store_data, extra_data):\n    extra_df = pd.read_parquet(extra_data)\n    merged_df = store_data.merge(extra_df, on = \"index\")\n    return merged_df\n    \n# Call the extract() function and store it as the \"merged_df\" variable\nprint(merged_df)\n",
    "outputsMetadata": {
     "0": {
      "height": 311,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "import fastparquet\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca21308c-36a8-49d7-adbc-dca20f83091e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 150,
    "lastExecutedAt": 1736859244311,
    "lastExecutedByKernel": "58b67199-41fb-415b-86ed-8438f98f5dab",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "grocery_sales",
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {
       "quickFilterText": ""
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "#J'ai téléchargé grocery_sales en format csv depuis la table PostgreSQL\n",
    "grocery_sales = pd.read_csv(\"grocery_sales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b858ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'extraction\n",
    "def extract(store_data, extra_data):\n",
    "    extra_df = pd.read_parquet(extra_data)\n",
    "    merged_df = store_data.merge(extra_df, on = \"index\")\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a3865c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J'appelle la fonction extract() qui fusionne les données extraites avec celles qu'on a déjà pour stocker dans la variable \"merged_df\"\n",
    "merged_df = extract(grocery_sales, \"extra_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e654505b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Store_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>3.0</td>\n",
       "      <td>151315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>26</td>\n",
       "      <td>11737.12</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>3.0</td>\n",
       "      <td>151315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>17</td>\n",
       "      <td>13223.76</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>3.0</td>\n",
       "      <td>151315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>45</td>\n",
       "      <td>37.44</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>151315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>28</td>\n",
       "      <td>1085.29</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>151315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231517</th>\n",
       "      <td>231517</td>\n",
       "      <td>232414</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-05-06</td>\n",
       "      <td>8</td>\n",
       "      <td>49471.07</td>\n",
       "      <td>0</td>\n",
       "      <td>55.75</td>\n",
       "      <td>4.192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.514367</td>\n",
       "      <td>8.212</td>\n",
       "      <td>3.0</td>\n",
       "      <td>203819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231518</th>\n",
       "      <td>231518</td>\n",
       "      <td>232415</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-05-06</td>\n",
       "      <td>50</td>\n",
       "      <td>1210.00</td>\n",
       "      <td>0</td>\n",
       "      <td>55.75</td>\n",
       "      <td>4.192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.514367</td>\n",
       "      <td>8.212</td>\n",
       "      <td>3.0</td>\n",
       "      <td>203819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231519</th>\n",
       "      <td>231519</td>\n",
       "      <td>232416</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-05-06</td>\n",
       "      <td>87</td>\n",
       "      <td>25893.32</td>\n",
       "      <td>0</td>\n",
       "      <td>55.75</td>\n",
       "      <td>4.192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.514367</td>\n",
       "      <td>8.212</td>\n",
       "      <td>3.0</td>\n",
       "      <td>203819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231520</th>\n",
       "      <td>231520</td>\n",
       "      <td>232417</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-05-06</td>\n",
       "      <td>85</td>\n",
       "      <td>1357.83</td>\n",
       "      <td>0</td>\n",
       "      <td>55.75</td>\n",
       "      <td>4.192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.514367</td>\n",
       "      <td>8.212</td>\n",
       "      <td>3.0</td>\n",
       "      <td>203819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231521</th>\n",
       "      <td>231521</td>\n",
       "      <td>232418</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-05-06</td>\n",
       "      <td>35</td>\n",
       "      <td>3648.91</td>\n",
       "      <td>0</td>\n",
       "      <td>55.75</td>\n",
       "      <td>4.192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231522 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   index  Store_ID        Date  Dept  Weekly_Sales  \\\n",
       "0                0       0         1  2010-02-05     1      24924.50   \n",
       "1                1       1         1  2010-02-05    26      11737.12   \n",
       "2                2       2         1  2010-02-05    17      13223.76   \n",
       "3                3       3         1  2010-02-05    45         37.44   \n",
       "4                4       4         1  2010-02-05    28       1085.29   \n",
       "...            ...     ...       ...         ...   ...           ...   \n",
       "231517      231517  232414        24  2011-05-06     8      49471.07   \n",
       "231518      231518  232415        24  2011-05-06    50       1210.00   \n",
       "231519      231519  232416        24  2011-05-06    87      25893.32   \n",
       "231520      231520  232417        24  2011-05-06    85       1357.83   \n",
       "231521      231521  232418        24  2011-05-06    35       3648.91   \n",
       "\n",
       "        IsHoliday  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
       "0               0        42.31       2.572        0.0        0.0        0.0   \n",
       "1               0        42.31       2.572        0.0        0.0        0.0   \n",
       "2               0        42.31       2.572        0.0        0.0        0.0   \n",
       "3               0        42.31       2.572        0.0        0.0        0.0   \n",
       "4               0        42.31       2.572        0.0        0.0        0.0   \n",
       "...           ...          ...         ...        ...        ...        ...   \n",
       "231517          0        55.75       4.192        0.0        0.0        0.0   \n",
       "231518          0        55.75       4.192        0.0        0.0        0.0   \n",
       "231519          0        55.75       4.192        0.0        0.0        0.0   \n",
       "231520          0        55.75       4.192        0.0        0.0        0.0   \n",
       "231521          0        55.75       4.192        0.0        0.0        0.0   \n",
       "\n",
       "        MarkDown4  MarkDown5         CPI  Unemployment  Type      Size  \n",
       "0             0.0        0.0  211.096358         8.106   3.0  151315.0  \n",
       "1             0.0        0.0  211.096358         8.106   3.0  151315.0  \n",
       "2             0.0        0.0  211.096358         8.106   3.0  151315.0  \n",
       "3             0.0        0.0  211.096358           NaN   3.0  151315.0  \n",
       "4             0.0        0.0  211.096358           NaN   3.0  151315.0  \n",
       "...           ...        ...         ...           ...   ...       ...  \n",
       "231517        0.0        0.0  134.514367         8.212   3.0  203819.0  \n",
       "231518        0.0        0.0  134.514367         8.212   3.0  203819.0  \n",
       "231519        0.0        0.0  134.514367         8.212   3.0  203819.0  \n",
       "231520        0.0        0.0  134.514367         8.212   3.0  203819.0  \n",
       "231521        NaN        NaN         NaN           NaN   NaN       NaN  \n",
       "\n",
       "[231522 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1459f05d-cdec-4252-95d1-77b4c12ca211",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1728061957669,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "print(merged_df.columns.tolist())",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'index', 'Store_ID', 'Date', 'Dept', 'Weekly_Sales', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Type', 'Size']\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "948be565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0        int64\n",
      "index             int64\n",
      "Store_ID          int64\n",
      "Date             object\n",
      "Dept              int64\n",
      "Weekly_Sales    float64\n",
      "IsHoliday         int64\n",
      "Temperature     float64\n",
      "Fuel_Price      float64\n",
      "MarkDown1       float64\n",
      "MarkDown2       float64\n",
      "MarkDown3       float64\n",
      "MarkDown4       float64\n",
      "MarkDown5       float64\n",
      "CPI             float64\n",
      "Unemployment    float64\n",
      "Type            float64\n",
      "Size            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d3c25e2-e7d8-4c33-9be0-d45f03b2cf43",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1728061957721,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Create the transform() function with one parameter: \"raw_data\"\ndef transform(raw_data):\n    raw_data.fillna(value=raw_data.mean(), inplace=True)\n    raw_data['Month'] = raw_data['Date'].dt.month\n    raw_data = raw_data.loc[raw_data['Weekly_Sales'] > 10000]\n    raw_data = raw_data.drop([\"index\",'Temperature','Date', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5','Type', 'Size'], axis=1)\n    return raw_data"
   },
   "outputs": [],
   "source": [
    "# Une fonction transform() avec un seul paramètre : raw_data\n",
    "def transform(raw_data):\n",
    "    raw_data.fillna(raw_data.select_dtypes(include=[\"number\"]).mean(), inplace=True)\n",
    "    raw_data[\"Date\"] = pd.to_datetime(raw_data[\"Date\"], errors=\"coerce\")\n",
    "    raw_data['Month'] = raw_data['Date'].dt.month\n",
    "    raw_data = raw_data.loc[raw_data['Weekly_Sales'] > 10000]\n",
    "    raw_data = raw_data.drop([\"index\",'Temperature','Date', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5','Type', 'Size'], axis=1)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "620b7289-06cd-4205-be9e-a50dc8d36cf0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 67,
    "lastExecutedAt": 1728061957788,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Call the transform() function and pass the merged DataFrame\nclean_data = transform(merged_df)\nprint(clean_data)",
    "outputsMetadata": {
     "0": {
      "height": 311,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  Store_ID  Dept  Weekly_Sales  IsHoliday         CPI  \\\n",
      "0                0         1     1      24924.50          0  211.096358   \n",
      "1                1         1    26      11737.12          0  211.096358   \n",
      "2                2         1    17      13223.76          0  211.096358   \n",
      "5                5         1    79      46729.77          0  211.096358   \n",
      "6                6         1    55      21249.31          0  211.096358   \n",
      "...            ...       ...   ...           ...        ...         ...   \n",
      "231513      231513        24    40      45396.26          0  134.514367   \n",
      "231515      231515        24    93      41295.84          0  134.514367   \n",
      "231516      231516        24     9      24024.18          0  134.514367   \n",
      "231517      231517        24     8      49471.07          0  134.514367   \n",
      "231519      231519        24    87      25893.32          0  134.514367   \n",
      "\n",
      "        Unemployment  Month  \n",
      "0           8.106000    2.0  \n",
      "1           8.106000    2.0  \n",
      "2           8.106000    2.0  \n",
      "5           7.500052    2.0  \n",
      "6           7.500052    2.0  \n",
      "...              ...    ...  \n",
      "231513      8.212000    5.0  \n",
      "231515      8.212000    5.0  \n",
      "231516      8.212000    5.0  \n",
      "231517      8.212000    5.0  \n",
      "231519      8.212000    5.0  \n",
      "\n",
      "[106231 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#On appelle transform() sur la variable \"merged_df\"\n",
    "clean_data = transform(merged_df)\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d09e72c0-0844-4d0d-95f0-7761b9643d12",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1728061957837,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "print(clean_data.columns.tolist())",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Store_ID', 'Dept', 'Weekly_Sales', 'IsHoliday', 'CPI', 'Unemployment', 'Month']\n"
     ]
    }
   ],
   "source": [
    "print(clean_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b19b15e3-6624-47a9-927f-d3f12fe8212d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1728061957885,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Create the avg_weekly_sales_per_month function that takes in the cleaned data from the last step\ndef avg_weekly_sales_per_month(clean_data):\n    data = clean_data[['Month','Weekly_Sales']]\n    data = data.groupby('Month').agg(Avg_Sales = (\"Weekly_Sales\",'mean')).reset_index().round(2)\n    return data"
   },
   "outputs": [],
   "source": [
    "# Fonction avg_weekly_sales_per_month qui prend en paramètre le dataset nettoyé\n",
    "def avg_weekly_sales_per_month(clean_data):\n",
    "    data = clean_data[['Month','Weekly_Sales']]\n",
    "    data = data.groupby('Month').agg(Avg_Sales = (\"Weekly_Sales\",'mean')).reset_index().round(2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe875e27-b0cf-4e52-994e-4ae1fe6e8876",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1728061957933,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Call the avg_weekly_sales_per_month() function and pass the cleaned DataFrame\nagg_data = avg_weekly_sales_per_month(clean_data)\nprint(agg_data)",
    "outputsMetadata": {
     "0": {
      "height": 290,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Month  Avg_Sales\n",
      "0     1.0   33174.18\n",
      "1     2.0   34333.33\n",
      "2     3.0   33220.89\n",
      "3     4.0   33392.37\n",
      "4     5.0   33339.89\n",
      "5     6.0   34582.47\n",
      "6     7.0   33922.76\n",
      "7     8.0   33644.79\n",
      "8     9.0   33258.05\n",
      "9    10.0   32736.99\n",
      "10   11.0   36594.03\n",
      "11   12.0   39238.80\n"
     ]
    }
   ],
   "source": [
    "#Exécution de avg_weekly_sales_per_month(clean_data)\n",
    "agg_data = avg_weekly_sales_per_month(clean_data)\n",
    "print(agg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "921cb123-3153-4334-bdeb-9bb227fdc530",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1728061957981,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Create the load() function that takes in the cleaned DataFrame and the aggregated one with the paths where they are going to be stored\ndef load(full_data,full_data_file_path, agg_data, agg_data_file_path):\n    full_data.to_csv(full_data_file_path , index=False)\n    agg_data.to_csv(agg_data_file_path, index=False)\n    pass"
   },
   "outputs": [],
   "source": [
    "# Fonction load qui prend en paramètres clean_data , agg_data et leurs chemins\n",
    "def load(full_data,full_data_file_path, agg_data, agg_data_file_path):\n",
    "    full_data.to_csv(full_data_file_path , index=False)\n",
    "    agg_data.to_csv(agg_data_file_path, index=False)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f518ad5c-214e-474b-80bd-827b0c0e1536",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 413,
    "lastExecutedAt": 1728061958394,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Call the load() function and pass the cleaned and aggregated DataFrames with their paths   \nload(clean_data,\"clean_data.csv\",agg_data,\"agg_data.csv\")"
   },
   "outputs": [],
   "source": [
    "#Appel de load() pour créer les fichiers csv clean_data et agg_data \n",
    "load(clean_data,\"clean_data.csv\",agg_data,\"agg_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61b5f58a-70cb-40b3-bdbe-20b4079276e3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1728061958445,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Create the validation() function with one parameter: file_path - to check whether the previous function was correctly executed\nfrom pathlib import Path\n\ndef validation(file_path):\n    try:\n        my_file = Path(file_path)\n        with open(my_file, 'r') as file:\n            print(\"The file exists.\")\n    except FileNotFoundError:\n        print(\"The file does not exist.\")"
   },
   "outputs": [],
   "source": [
    "# Si le fichier existe validation() retourne \"The file exists\" sinon \"The file does not exist\"\n",
    "from pathlib import Path\n",
    "\n",
    "def validation(file_path):\n",
    "    try:\n",
    "        my_file = Path(file_path)\n",
    "        with open(my_file, 'r') as file:\n",
    "            print(\"The file exists.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df1659ff-41c4-4a92-9812-80c6eaa02b90",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1728061958493,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Call the validation() function and pass first, the cleaned DataFrame path, and then the aggregated DataFrame path\nvalidation(\"clean_data.csv\")",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists.\n"
     ]
    }
   ],
   "source": [
    "# On vérifie l'existence de clean_data.csv\n",
    "validation(\"clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cc77411-d673-49b8-97f8-a5901ac23da6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1728061958541,
    "lastExecutedByKernel": "01ee7821-a58c-45fe-8a47-13851ac88d51",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "validation(\"agg_data.csv\")",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists.\n"
     ]
    }
   ],
   "source": [
    "# On vérifie l'existence de agg_data.csv\n",
    "validation(\"agg_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
